project_name: seg-road-cracks

# =========================== Dataset ==========================
dataset:
  classes: ["cracks"]                                       # class to segment
  batch_size: 4                                             # training batch size
  shuffle: true
  num_workers: 5
  drop_last: false

# =========================== Model ==========================
model:
  arch: unet                                              # segmentation model (e.g. unet, deeplab, deeplabv3+)
  backbone: timm-efficientnet-b3                          # model backbone
  weights: imagenet                                       # pretrained weights (e.g. imagenet, noisy-student)

# =========================== Trainer =========================
trainer:
  precision: 16
  gpus: 1                                                 # number of gpus
  gradient_clip_val: 0.0                                  # gradient clip (0 to disable)
  log_gpu_memory: true                                    # pytorch-lightning gpu log
  max_epochs: 500                                         # training epochs

# ========================= Loss + Optimizer + LR Scheduler ===========
loss:
  criterion: jaccard                                      # loss during training (jaccard is the best)
  mode: binary                                            # binary, multilabel, multiclass

optimizer:
  algo: sgd                                               # which optimizer to use
  lr: 0.4                                                 # learning rate
  momentum: 0.0                                           # momentum
  weight_decay: 0.0                                       # weight decay

scheduler:
  algo: cosine_annealing_warm                             
  t_0: 10                                                 # number of iterations for the first restart (e.g. 10 means afer 10 epochs)
  t_mult: 2                                               # a factor increases t_i after a restart
  eta_min: 0                                              # minimum learning rate

transform:
  input_size: [512, 512]                                  # model input size (int, list, tuple)
  hflip_p: .5
  scale_limit: 0.5
  rotate_limit: 0
  shift_limit: 0.1
  shif_scale_rotate_p: 1
  border_mode: 0
  gauss_noise_p: 0.5
  perspective_p: 0.5
  one_of_p: 0.9
  blur_limit: 3
  mean: [0.485, 0.456, 0.406]                             # to not apply normalization put [0, 0, 0]
  std: [0.229, 0.224, 0.225]                              #  to not apply normalization put [1, 1, 1]




                  
    
      

